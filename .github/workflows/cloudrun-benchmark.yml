# Cloud Run Benchmark CI
#
# Runs a quick smoke test of the Cloud Run benchmark harness to validate
# it works without waiting for true cold starts.
#
# Triggers:
# - Manual (workflow_dispatch) for on-demand testing
# - Weekly schedule for regular validation
# - On changes to tests/cloudrun/** (PR only)

name: 'Cloud Run Benchmark'

on:
  workflow_dispatch:
    inputs:
      config:
        description: 'Configuration file to use'
        required: false
        default: 'quick.yaml'
        type: choice
        options:
          - debug.yaml
          - quick.yaml
          - default.yaml
      services:
        description: 'Comma-separated services to test (empty = use config)'
        required: false
        default: ''
        type: string

  schedule:
    # Run weekly on Sunday at 2am UTC
    - cron: '0 2 * * 0'

  pull_request:
    branches: [main]
    paths:
      - 'tests/cloudrun/**'
      - '.github/workflows/cloudrun-benchmark.yml'

env:
  AR_REPOSITORY: discord-services

# Only allow one benchmark run at a time
concurrency:
  group: cloudrun-benchmark
  cancel-in-progress: false

jobs:
  benchmark:
    name: Run Benchmark
    runs-on: ubuntu-latest
    # Only run on schedule/dispatch if secrets are available
    if: github.event_name == 'pull_request' || github.repository == 'pmgledhill102/discord-bot-test-suite'

    permissions:
      contents: read
      id-token: write # Required for Workload Identity Federation

    steps:
      - name: Checkout code
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - name: Set up Go
        uses: actions/setup-go@7a3fe6cf4cb3a834922a1244abfce67bcef6a0c5 # v6.2.0
        with:
          go-version: '1.25'
          cache-dependency-path: tests/cloudrun/go.sum

      # Skip GCP auth for PRs (just validate code compiles)
      - name: Build benchmark tool
        working-directory: tests/cloudrun
        run: |
          go mod download
          go build -o cloudrun-benchmark ./cmd/cloudrun-benchmark

      - name: Validate configuration
        working-directory: tests/cloudrun
        run: |
          echo "Validating configuration files..."
          for config in configs/*.yaml; do
            echo "Checking $config"
            # Basic YAML validation
            python3 -c "import yaml; yaml.safe_load(open('$config'))"
          done

      # For PRs, just verify the code compiles and configs are valid
      - name: PR validation complete
        if: github.event_name == 'pull_request'
        run: |
          echo "PR validation complete - skipping GCP deployment"
          echo "Full benchmark runs on schedule or manual trigger only"

      # For schedule/dispatch, actually run the benchmark
      - name: Authenticate to GCP
        if: github.event_name != 'pull_request'
        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        if: github.event_name != 'pull_request'
        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1

      - name: Configure Docker for Artifact Registry
        if: github.event_name != 'pull_request'
        run: |
          gcloud auth configure-docker ${{ vars.GCP_REGION }}-docker.pkg.dev --quiet

      - name: Determine config and services
        if: github.event_name != 'pull_request'
        id: params
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            CONFIG="${{ github.event.inputs.config }}"
            SERVICES="${{ github.event.inputs.services }}"
          else
            # Schedule run uses quick config
            CONFIG="quick.yaml"
            SERVICES=""
          fi
          echo "config=${CONFIG}" >> "${GITHUB_OUTPUT}"
          echo "services=${SERVICES}" >> "${GITHUB_OUTPUT}"

      # Images are already in AR from service CI workflows (push to main)
      # The benchmark tool uses the 'latest' tag from AR

      - name: Run benchmark
        if: github.event_name != 'pull_request'
        working-directory: tests/cloudrun
        env:
          PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}
          REGION: ${{ vars.GCP_REGION }}
        run: |
          # Update config with project ID
          CONFIG_FILE="configs/${{ steps.params.outputs.config }}"
          sed -i "s/project_id: \"\"/project_id: \"${PROJECT_ID}\"/" "${CONFIG_FILE}"

          # Run benchmark
          SERVICES_ARG=""
          if [[ -n "${{ steps.params.outputs.services }}" ]]; then
            SERVICES_ARG="--services ${{ steps.params.outputs.services }}"
          fi

          # shellcheck disable=SC2086
          ./cloudrun-benchmark run \
            --config "${CONFIG_FILE}" \
            --output results \
            ${SERVICES_ARG}

      - name: Upload results
        if: github.event_name != 'pull_request' && always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: benchmark-results-${{ github.run_id }}
          path: tests/cloudrun/results/
          retention-days: 30

      - name: Cleanup on failure
        if: github.event_name != 'pull_request' && failure()
        working-directory: tests/cloudrun
        env:
          PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}
          REGION: ${{ vars.GCP_REGION }}
        run: |
          echo "Cleaning up resources after failure..."
          ./scripts/cleanup.sh || true

      - name: Summary
        if: github.event_name != 'pull_request'
        run: |
          {
            echo "## Benchmark Results"
            echo ""
            RESULTS_FILE=$(find tests/cloudrun/results -name 'results.md' 2>/dev/null | head -1)
            if [[ -n "${RESULTS_FILE}" && -f "${RESULTS_FILE}" ]]; then
              cat "${RESULTS_FILE}"
            else
              echo "No results file found"
            fi
          } >> "${GITHUB_STEP_SUMMARY}"
